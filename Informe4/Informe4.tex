\documentclass[12pt]{article}

    \title{Informe 4. Urano App} 
    
    \author {Ronald Cardona
    \and Anderson Grajales
    \and Sebastian Valencia
    \and Julian Sanchez}
    
    
    % Packages
    \usepackage[spanish]{babel}
    \selectlanguage{spanish} 
    \usepackage[utf8]{inputenc}
    \usepackage[spanish, onelanguage]{algorithm2e} %for psuedo code
    \usepackage{amsthm}
    \usepackage{amsmath}
    
    \newtheorem{definition}{Definición}[section]
    \newtheorem{theorem}{Teorema}[section]
    
    \begin{document}
        \maketitle
        \section{Funciones de apoyo}
        Esta seccion muestra algunas funciones que son necesarias para lograr una correcta implementacion de los metodos para la solucion numerica de sistemas de ecuaciones lineales.
        \subsection{Determinantes}
        \begin{definition}
            Sea $A = [a_{ij}]$ una matriz de tamaño $n \times n$. El cofactor $C_{ij}$ de $a_{ij}$ se define como $(-1)^{i+j}\det {M_{ij}}$, donde $M_{ij}$ es la matriz de tamaño $(n - 1) \times (n - 1)$, que se obtiene al eliminar la fila $i$ y la columna $j$ de la matriz.\cite{algebralineal}
        \end{definition}
        \begin{theorem}
            Sea $A=[a_{ij}]$ una matriz de tamaño $n \times n$. \cite{algebralineal}
            \begin{itemize}
                \item Para cada $1\leq i \leq n$ se cumple que:
                $\det {A} = a_{i1}C_{i1} + a_{i2}C_{i2} + ... + a_{in}C_{in}$
                \item Para cada $1\leq j \leq n$ se cumple que:
                $\det {A} = a_{1j}C_{1j} + a_{2j}C_{2j} + ... + a_{nj}C_{nj}$
            \end{itemize}
        \end{theorem}
        De acuerdo al teorema 1.1 se puede definir una ecuación de recurrencia para encontrar el determinante de una matriz $A = [a_{ij}]$ de la siguiente manera:
        
        \begin{equation}
        det(A, n)_{1\leq i \leq n}=\begin{cases}
        a_{11}, & \text{if $n = 1$}.\\
        (-1)^{i+1} \times a_{1i} \times det(A', n - 1) , & \text{if $n > 1$}.
        \end{cases}
        \end{equation}
        Donde $A'$ es la matriz que se obtiene al eliminar la columna $i$ y la fila $n$ de $A$. De esta manera, para una matriz $B$ de $n \times n$, la solución se entrega de la forma:
        $det(B, n)$.
        
        \subsection{Multiplicación de matrices}
        \begin{definition}
            Dadas las matrices $A \in M_{m\times n}$ y $B \in M_{n\times p}$, entonces el producto de $A$ con $B$, denotado $AB$, es una matriz $C \in M_{m\times p}$, dada por: \cite{algebralineal}
            \[
                c_{ij} = a_{i1}b_{1j} + a_{i2}b_{2j} + a_{i3}b_{3j} + \dots + a_{in}b_{nj} = \sum_{k = 1}^{n}{a_{ik}b_{kj}}		
            \]
            con $i = 1, ..., m$ y $j = 1, ..., p$
        \end{definition}

        \subsection{Escalonamiento de matrices}
        \begin{definition}
            Sea $A = [a_{ij}]$ una matriz de $n \times n$. Decimos que $A$ está escalonada si $\forall{i,j}, 1\leq i \leq j \leq n$, $a_{ij} = 0$.
        \end{definition}
        \begin{algorithm}[H]
            \caption{Algoritmo para escalonar matrices}
            Leer $A$, $b$ \\
            \uIf{$A \not \in \Re^{n\times n}$ \textbf{ó} $b \not\in \Re^{n}$}
            {$A$ debe ser cuadrada y $b$ debe ser un arreglo de $n$ posiciones}
            \uElseIf{$\det{A} = 0$}
            {$A$ debe ser invertible}
            \Else
            {
                \For{$k = 1$ \KwTo $n-1$}
                {
                    \If{$A_{kk} = 0$}
                    {
                        $j \leftarrow k + 1$\\
                        \While{$j < n$ \textbf{y} $A_{jk} = 0$}
                        {
                            $j \leftarrow j + 1$
                        }
                        \If{$j < n$}
                        {
                            \For{$l = k$ \KwTo $n$}
                            {
                                $A_{kl} \leftarrow A_{kl} + A_{jl}$
                            }
                            $b_k \leftarrow b_k + b_j$
                        }
                    }
                    \For{$i = k + 1$ \KwTo $n$}
                    {
                        \If{$A_{ki} \not = 0$}
                        {
                            $m \leftarrow \frac{A_{ik}}{A_{kk}}$\\
                            \For{$l = k$ \KwTo $n$}
                            {
                                $A_{il} \leftarrow A_{il} - m\times A_{kl}$
                            }
                            $b_i \leftarrow b_i - m \times b_k$
                        }
                    }
                }
            }
            La solución $(A, b)$
        \end{algorithm}

        \subsection{Sustitución Regresiva}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Sustitución Regresiva}
            Leer $A$, $b$ \\
            $marks \leftarrow NULL$ \\
            $n \leftarrow Len(A) - 1$ \\ 
            $x \leftarrow 0$ \\
            $x_{n} \leftarrow \frac{b_n}{A_{nn}}$ \\
            \For{$i \leftarrow n - 1$ \KwTo $-1$}
            {
                $sumatoria \leftarrow 0$ \\
                \For{$p \leftarrow i + 1$ \KwTo $n + 1$}
                {
                    $sumatoria \leftarrow sumatoria + A_{ip}*x_{p}$\\
                }
                $x_{i} \leftarrow b_{i}$\\
            }
            \uIf{$marks \neq NULL$}
            {
                $marcas[Len(A)] \leftarrow 0$\\
                \For{$i \leftarrow 0$ \KwTo $Len(A)$}
                {
                    $marcas_{marks_{i}} \leftarrow x_{i}$\\
                }
                Retornar $marcas$\\
            }
            Retornar $x$\\
        \end{algorithm}

        \subsection{Sustitución Progresiva}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Sustitución Progresiva}
            Leer $A$, $b$ \\
            $n \leftarrow Len(A) - 1$\\
            $x \leftarrow 0$\\
            $x_0 \leftarrow \frac{b_0}{A_00}$\\
            \For{$i \leftarrow 1$ \KwTo $n + 1$}
            {
                $sumatoria \leftarrow 0$\\
                \For{$p \leftarrow 0$ \KwTo $i$}
                {
                    $sumatoria \leftarrow sumatoria + A_{ip}*x_{p}$\\
                }
                $x_{i} \leftarrow \frac{b_{i} - sumatoria}{A_{ii}}$\\
            }
            Retornar $x$\\
        \end{algorithm}

        \section{Solucion Numerica de Sistemas de Ecuaciones Lineales}
        Muchos problemas del mundo real se formulan como sistemas de ecuaciones de $n$ variables y $m$ incógnitas que bajo condiciones ideales($n$ y $m$ no son valores muy grandes), se pueden resolver de manera analítica. Sin embargo, cuando $n$ y $m$ tienden a ser valores muy grandes la solución analítica a estos problemas es muy difícil de calcular ya que requiere de mucho tiempo y claramente no es la forma más eficiente hacerlo. Debido a esto, desde el campo del \textit{Análisis Numérico} se plantean diversas formas computacionales, ya sean algoritmos u otras técnicas que nos permitan resolver estos sistemas rápidamente, teniendo en cuenta que hay una \textit{\textbf{propagación de error}} en cada cálculo dependiendo de la capacidad de la computadora donde se ejecuten estos.
        En  esta seccion se presentan algunos algoritmos numéricos que son de gran ayuda a la hora de resolver sistemas de ecuaciones lineales.
        
        \subsection{Eliminacion Gaussiana con Pivoteo Parcial}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Pivoteo Parcial}
            Leer $A$, $b$, $n$, $k$ \\
            $mayor \leftarrow |A_{kk}|$\\
            $filaMayor \leftarrow k$\\
            \For{$s \leftarrow k + 1$ \KwTo $n$}
            {
                \uIf{$|A_{sk}| > mayor $}
                {
                    $mayor \leftarrow |A_{sk}| $ \\
                    $filaMayor \leftarrow s$\\
                }
            }
            \uIf {$mayor = 0$}
            {
                El sistema no tiene solucion unica
            } \uElseIf {$filaMayor \neq k$}
            {
                $temp \leftarrow A_{filaMayor}$\\
                $A_{filaMayor} \leftarrow temp$\\
                $A_{k} \leftarrow A_{filaMayor}$\\
                $temp \leftarrow b_{filaMayor}$\\
                $b_{filaMayor} \leftarrow b_{k}$\\
                $b_{k} \leftarrow b_{filaMayor}$
            }
            Retornar($A$, $b$)
        \end{algorithm}

        \subsection{Eliminacion Gaussiana con Pivoteo Total}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Pivoteo Total}
            Leer $A$, $b$, $n$, $k$ \\
            $mayor \leftarrow |A_{kk}|$\\
            $filaMayor \leftarrow k$\\
            $columnaMayor \leftarrow k$\\
            \For{$r \leftarrow k$ \KwTo $n$}
            {
                \For{$s \leftarrow k$ \KwTo $n$}
                {
                    \uIf{$|A_{rs}| > mayor $}
                    {
                        $mayor \leftarrow |A_{rs}| $ \\
                        $filaMayor \leftarrow r$\\
                        $columnaMayor \leftarrow s$
                    }
                }
            }
            \uIf {$mayor = 0$}
            {
                El sistema no tiene solucion unica
            } \uElse {
                \uIf {$filaMayor \neq k$}
                {
                    $temp \leftarrow A_{k}$\\
                    $A_{k} \leftarrow A_{filaMayor}$\\
                    $A_{filaMayor} \leftarrow temp$\\
                    $temp \leftarrow b_{k}$\\
                    $b_{k} \leftarrow b_{filaMayor}$\\
                    $b_{filaMayor} \leftarrow temp$\\
                }
                \uIf {$columnaMayor \neq k$}
                {
                    $temp \leftarrow A_{0 columnaMayor}$\\
                    $A_{0 columnaMayor} \leftarrow A_{0k}$\\
                    $A_{0k} \leftarrow temp$\\
                    $temp \leftarrow b_{0 columnaMayor}$\\
                    $b_{0 columnaMayor} \leftarrow b_{0k}$\\
                    $b_{0k} \leftarrow temp$\\
                    $temp \leftarrow marcas_{k}$\\
                    $marcas_{k} \leftarrow marcas_{columnaMayor}$\\
                    $marcas_{columnaMayor \leftarrow temp}$\\
                }
                Retornar($A$, $b$)\\
            }
            
        \end{algorithm}


        \section{Metodos de Factorizacion LU}
        Dada una martiz cuadrada $A$ de orden $n x n$, se halla una matriz $L$
        triangular inferior y una matriz $U$ triangular superior tal que $A = LU$
        Este tipo de sistemas se resuelven de manera trivial haciendo uso de los ya conocidos
        metodos de sustitucion regresiva y sustitucion progresiva, ya que las matrices son
        triangulares.

        \subsection{Factorizacion LU con Gaussiana Simple}
        En este caso la matriz $U$ corresponde a la matriz $A$ en su forma escalonada. Y la matriz $L$ se forma ubicando 1's en la diagonal y los multiplicadores $M_{ij}$ en las entradas correspondientes.
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Factorizacion LU con Gaussiana Simple}
            Leer $A$, $b$ \\
            $(L, U) \leftarrow Escalonar(A, b)$\\ 
            $z \leftarrow SustitucionProgresiva(L, b)$\\
            $x \leftarrow SustitucionRegresiva(U, z)$\\
            Retornar $x$\\
        \end{algorithm}

        \subsection{Factorizacion LU con Gaussiana y Pivoteo Parcial}
        La matriz $L$ se construye con base en los multiplicadores ubicados segun sus respectivos indices y con 1's en la diagonal, y la matriz $U$ es la matriz resultante del oproceso de eliminacion 
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Factorizacion LU con Gaussiana y Pivoteo Parcial}
            Leer $A$, $b$ \\
            $(L, U) \leftarrow EscalonarParcial(A, b)$\\
            $z \leftarrow SustitucionProgresiva(L, b)$\\
            $x \leftarrow SustitucionRegresiva(U, z)$\\
            Retornar $x$\\
        \end{algorithm}


        \subsection{Factorizacion de Doolittle}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Factorizacion de Doolittle}
            Leer $A$, $b$\\
            \uIf{A no es cuadrada}
            {
                Retornar Matriz no cuadrada
            }
            {
                $n = longitud(A_{0})$\\ 
                $L \leftarrow MatrizIdentidad(n)$\\
                $U \leftarrow MatrizIdentidad(n)$\\
                \For{$i \leftarrow 0$ \KwTo $n$}
                {
                    \For{$k \leftarrow i$ \KwTo $n$}
                    {
                        $u \leftarrow A_{ik}$\\
                        \For{$numero \leftarrow 0$ \KwTo $i$}
                        {
                            $u \leftarrow u - L_{i, numero} * U_{numero, k}$\\
                        }
                        $L_{ik} \leftarrow u/L_{ii}$\\
                    }
                    \For{$j \leftarrow i + 1$ \KwTo $n$}
                    {
                        $suma \leftarrow A_{ji}$\\
                        \For{$numero \leftarrow 0$ \KwTo $j$}
                        {
                            $suma \leftarrow suma - L_{j, numero} * U_{numero, i}$\\
                        }
                        $L_{ji} \leftarrow \frac{suma}{U_{ii}}$\\
                    }
                }
                $z \leftarrow SustitucionProgresiva(L, b)$\\
                $x \leftarrow SustitucionRegresiva(U, z)$\\
                Retornar $x$
            }


            
        \end{algorithm}

        \subsection{Factorizacion de Choletsky $A = LDL$}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Factorizacion de Choletsky}
            Leer $A$\\
            $n \leftarrow longitud(A)$\\
            $L[n][n] \leftarrow 0$\\
            $U[n][n] \leftarrow 0$\\
            \For{$k \leftarrow 0$ \KwTo $n$}
            {
                $suma_p \leftarrow 0.0$\\
                \For{$p \leftarrow 0 $ \KwTo $k$}
                {
                    $suma1 \leftarrow L_{kp} * U_{pk}$\\
                }
                $L_{kk} \leftarrow (A_{kk} - suma1)^{0.5}$\\
                $U_{kk} \leftarrow L_{kk}$\\
                \For{$i \leftarrow k$ \KwTo $n$}
                {
                    $suma2 \leftarrow 0.0$\\
                    \For{$p \leftarrow 0$ \KwTo $k$}
                    {
                        $suma2 \leftarrow suma2 + L_{ip} * U_{pk})$\\
                    }
                    $L_{ik} \leftarrow \frac{A_{ik} - suma2}{U_{kk}}$\\
                }

                \For{$j \leftarrow k + 1$ \KwTo $n$}
                {
                    $suma3 \leftarrow 0$\\
                    \For{$p \leftarrow 0$ \KwTo $k$}
                    {
                        $suma3 \leftarrow suma3 + L_{kp} * U_{pj})$\\
                    }
                    $U_{kj} \leftarrow \frac{A_{kj} - suma3}{L_{kk}}$\\
                }

            }
            Retornar $L, U$

        \end{algorithm}

        \subsection{Factorizacion de Crout $A = LDU$}
        
        \begin{algorithm}[H]
            \caption{Algoritmo de Factorizacion de Crout}
            Leer $A$, $b$\\
            \uIf{A no es cuadrada}
            {
                Retornar Matriz no cuadrada
            }
            {
                $n = longitud(A_{0})$\\ 
                $L \leftarrow 0$\\
                $U \leftarrow MatrizIdentidad(n)$\\
                \For{$i \leftarrow 0$ \KwTo $n$}
                {
                    \For{$j \leftarrow i$ \KwTo $n$}
                    {
                        $suma \leftarrow A_{ji}$\\
                        \For{$numero \leftarrow 0$ \KwTo $j$}
                        {
                            $suma \leftarrow suma - L_{j, numero} * U_{numero, i}$\\
                        }
                        $L_{ji} \leftarrow suma$\\
                    }
                    \For{$k \leftarrow i + 1$ \KwTo $n$}
                    {
                        $u \leftarrow A_{ik}$\\
                        \For{$numero \leftarrow 0$ \KwTo $i$}
                        {
                            $u \leftarrow u - L_{i, numero} * U_{numero, k}$\\
                        }
                        $L_{ik} \leftarrow \frac{u}{L_{ii}}$\\
                    }
                }
                $z \leftarrow SustitucionProgresiva(L, b)$\\
                $x \leftarrow SustitucionRegresiva(U, z)$\\
                Retornar $x$
            }

        \end{algorithm}

        \section{Metodos Indirectos}
        Para encontrar soluciones a un sistema de la forma $Ax = b$, encontraremos vectores $x^{(i)}$, aproximaciones a la solucion, a partir de un vector inicial $x^{(0)}$, hasta que se cumpla cierta tolerancia respecto a una norma establecida. Cada $x^{(i)}$ se genera a partir de una funcion analoga a la funcion de punto fijo $G(x) = x$. 

        \subsection{Metodo de Jacobi}

        \begin{algorithm}[H]
            \caption{Algoritmo del metodo de Jacobi}
            Leer $A$, $b$, $tol$, $x0$, $niter$\\
            $cont \leftarrow 1$\\
            $dispersion \leftarrow tol + 1$\\
            $solucion.add((0, x0))$\\
            \While{$dispersion > tol AND cont < niter$}
            {
                $x1 \leftarrow calcularNuevoJacobi(A, b, x0)$\\
                $dispersion \leftarrow normaCuadrada(x1, x0)$\\
                $ss.add((cont, x1, dispersion))$\\
                $x0 \leftarrow x1$\\
                $solucion.add(ss)$\\
                $cont \leftarrow cont + 1$\\
            }
            Retornar $solucion$\\
        \end{algorithm}
        
        
        \begin{algorithm}[H]
            \caption{Algoritmo para calcular el nuevo Jacobi}
            calcularNuevoJacobi($A$, $b$, $x0$)\\
            Leer $A$, $b$, $x0$\\
            $n \leftarrow longitud(x0)$\\
            \For{$i \leftarrow 0$ \KwTo $n$}
            {
                $suma \leftarrow 0.0$\\
                \For{$j \leftarrow 0 $ \KwTo $n$}
                {
                    \If{$j \neq i$}
                    {
                        $suma \leftarrow suma + A_{ij} * x0_j$\\
                    }
                }
                $x_i \leftarrow \frac{b_i - suma}{A_{ii}}$\\
            }
            Retornar $x$\\
        \end{algorithm}

        \begin{algorithm}[H]
            \caption{Algoritmo Norma Cuadrada}
            normaCuadrada($x1$, $x0$)\\
            Leer $x1$, $x0$\\
            $suma1 \leftarrow 0.0$\\
            $suma2 \leftarrow 0.0$\\
            \For{$i \leftarrow 0 $ \KwTo $longitud(x1)$}
            {
                $suma1 \leftarrow suma1 + (x1_i - x0_i)^2$\\
                $suma2 \leftarrow suma2 + x1_i^2$\\
            }
            Retornar $\sqrt{\frac{sum1}{sum2}}$\\
        \end{algorithm}

        \subsection{Metodo de Gauss-Seidel}
        
        \begin{algorithm}[H]
            \caption{Algoritmo del metodo de Gauss-Seidel}
            Leer $A$, $b$, $tol$, $x0$, $niter$\\
            $cont \leftarrow 1$\\
            $dispersion \leftarrow tol + 1$\\
            $solucion.add((0, x0))$\\
            \While{$dispersion > tol AND cont < niter$}
            {
                $x1 \leftarrow calcularNuevoGaussSeidel(A, b, x0)$\\
                $dispersion \leftarrow normaCuadrada(x1, x0)$\\
                $ss.add((cont, x1, dispersion))$\\
                $x0 \leftarrow x1$\\
                $solucion.add(ss)$\\
                $cont \leftarrow cont + 1$\\
            }
            Retornar $solucion$\\
        \end{algorithm}

        \begin{algorithm}[H]
            \caption{Algoritmo para calcular el nuevo GaussSeidel}
            calcularNuevoGaussSeidel($A$, $b$, $x0$)\\
            Leer $A$, $b$, $x0$\\
            $n \leftarrow longitud(x0)$\\
            $x \leftarrow x0$\\
            \For{$i \leftarrow 0$ \KwTo $n$}
            {
                $suma \leftarrow 0.0$\\
                \For{$j \leftarrow 0 $ \KwTo $n$}
                {
                    \If{$j \neq i$}
                    {
                        $suma \leftarrow suma + A_{ij} * x_j$\\
                    }
                }
                $x_i \leftarrow \frac{b_i - suma}{A_{ii}}$\\
            }
            Retornar $x$\\
        \end{algorithm}

        \section{Metodos Iterativos de Forma Matricial}

        \subsection{Gauss-Seidel con relajacion}
        \begin{algorithm}[H]
            \caption{Algoritmo del metodo SOR Gauss-Seidel}
            Leer $A$, $b$, $tol$, $x0$, $w$, $niter$\\
            $cont \leftarrow 1$\\
            $solucion.add((0))$\\
            \While{$dispersion > tol AND cont < niter$}
            {
                $x1 \leftarrow calcularNuevoGaussSeidelSOR(A, b, x0, w)$\\
                $dispersion \leftarrow normaMaximo(x1, x0)$\\
                $x0 \leftarrow x1$\\
                $solucion.add((cont, x1, dispersion))$\\
                $cont \leftarrow cont + 1$\\
            }
            Retornar $solucion$\\
        \end{algorithm}

        \begin{algorithm}[H]
            \caption{Algoritmo para calcular el nuevo Gauss-Seidel}
            calcularNuevoGaussSeidelSOR($A$, $b$, $x0$, $w$)\\
            Leer $A$, $b$, $x0$, $w$\\
            $n \leftarrow longitud(x0)$\\
            $x \leftarrow x0$\\
            \For{$i \leftarrow 0$ \KwTo $n$}
            {
                $suma \leftarrow 0.0$\\
                \For{$j \leftarrow 0 $ \KwTo $n$}
                {
                    \If{$j \neq i$}
                    {
                        $suma \leftarrow suma + A_{ij} * x_j$\\
                    }
                }
                $x_i \leftarrow \frac{(1 - w) * (x_i + w) * (b_i - suma)}{A_{ii}}$\\
            }
            Retornar $x$\\
        \end{algorithm}

        \begin{algorithm}[H]
            \caption{Algoritmo Norma Maximo}
            normaMaximo($x1$, $x0$)\\
            Leer $x1$, $x0$\\
            $max1 \leftarrow 0.0$\\
            $max2 \leftarrow 0.0$\\
            \For{$i \leftarrow 0 $ \KwTo $longitud(x1)$}
            {
                $max1 \leftarrow max(|x1_i - x0_i|, mx1)$\\
                $max2 \leftarrow max(|x1_i|, max2)$\\
            }
            Retornar $\frac{max1}{max2}$\\
        \end{algorithm}

        \section{Metodos de Interpolacion}

        \subsection{Metodos basados en sistemas de ecuaciones}
        \begin{theorem}
            Dados $n + 1$ puntos con la condicion de que $x_{i} \neq x_{j}$ para todo $i, j$ tal que $0 <= i, j <= n$, entonces existe un polinomio $p(x)$ de grado a lo sumo $n$ tal que para todo $i$, $0 <= i <= n$, se cumple que $p(x_{i}) = y_{i}$
        \end{theorem}

        Dado un conjunto con $n + 1$ puntos conocidos, entonces por el teorema anterior, existe un unico polinomio interpolante $p(x)$ de grado a lo sumo $n$. Luego, se puede considerar que el polinomio tiene la forma
    
        \begin{center}
            $p(x) = a_nx^n + a_{n-1}x^{n-1} + a_{n-2}x^{n-2} + ... + a_2x^2 + a_1x + a_0$\\
        \end{center}
            

        Para obtener el polinomio basta determinar el valor de todos los coeficientes
        \begin{center}
            $a_n, a_{n-1}, a_{n-2}, ..., a_2, a_1, a_0$\\
        \end{center}
        Esto genera un sistema de ecuaciones lineales que siempre es soluble.
        
        \begin{algorithm}[H]
            \caption{Algoritmo para obtener el polinomio interpolante por medio de la matriz de Vandermonde}
            Leer $puntos$\\
            definir $A, b, auxA$\\
            $n \leftarrow longitud(puntos)$\\
            \For{$punto \leftarrow puntos$}
            {
                $b.add(punto_{1})$\\
                \For{$i \leftarrow 1$ \KwTo $n + 1$}
                {
                    $auxA.add((punto_{0})^{n-i})$\\
                }
                $A.add(auxA)$\\
            }
            $Ab \leftarrow EscalonarMatriz(A, b)$\\
            $x \leftarrow SustitucionRegresiva(A, b)$\\
            Retornar $(A, b)$\\
        \end{algorithm}

        \subsection{Polinomio Interpolante de Newton con Diferencias Divididas}
        Dados $n + 1$ puntos $(x_0, y_0), (x_1, y_1) , ..., (x_n, y_n)$ el polinomio del teorema de Interpolacion se puede escribir asi:  
        \begin{center}
            $p(x) = b_0 + b_1(x - x_0) + b_2(x - x_0)(x - x_1) + ... + b_n(x - x_0)(x - x_1) ... (x - x_{n-1})$\\
        \end{center}
        Asi para hallar el polinomio $p_n(x)$ basta con allar los $b_n$.
        Supongamos que se conoce el siguiente conjunto de puntos ${(x_0, y_0), (x_1, y_1) , ..., (x_n, y_n)}$\\
        

        \begin{itemize}
            \item Diferencia dividida de orden 0 \\
                $f[x_k] = f(x_k)$\\
                $b_0 = f[x_0]$\\
            \item Primera diferencia dividida\\
                $f[x_k, x_{k+1}] = \frac{f[x_{k+1}] - f[x_k]}{x_{k+1} - x_k}$\\
                $b_1 = f[x_0, x_1]$\\
            \item n-esima diferencia dividida \\ 
                $f[x_k, ..., x_{k + n}] = \frac{f[x_{k+1}, x_{k+2}, ..., x_{k+n}] - f[x_k, x_{k+1}, ..., x_{k+n}]}{x_{k+n} - x_k}$\\
                $b_n = f[x_0, x_1, ..., x_n]$\\
        \end{itemize}
        
        \begin{algorithm}[H]
            \caption{Algoritmo para obtener la tabla de diferencias divididas}
            Leer $nPuntos, valor, x, y$\\
            $tabla [nPuntos][nPuntos]$\\
            \For{$i \leftarrow 0$ \KwTo $nPuntos$}
            {
                $tabla_i0 \leftarrow y_i$\\
                \For{$j \leftarrow 1$ \KwTo $i + 1$}
                {
                    $tabla_{ij} \leftarrow \frac{tabla_{i,j-1} - tabla_{i-1, j-1}}{x_i - x_{i-j}}$\\
                }
            }
            Retornar $tabla$\\
        \end{algorithm}

        \begin{center}
            \begin{tabular}{|l|l|l|l|l|l|l|l} \hline
            $n$ & $x_i$ & $f[x_i]$ & $1ra$ & $2da$ & $3ra$ & $4ta$ & $5ta$\\
            \hline \hline
            0 & 1 &  0.6747 & & & & & \\
            \hline 
            1 & 1.2 &  0.8491 & 0.8723 & & & & \\
            \hline
            2 & 1.4 &  1.1214 & 1.3610 & 1.2218 & & &\\
            \hline 
            3 & 1.6 &  1.4921 & 1.8536 & 1.2314 & 0.0160 & &\\
            \hline
            4 & 1.8 &  1.9607 & 2.3429 & 1.2233 & -0.0134 & -0.0368 &\\
            \hline
            5 & 2.0 &  2.5258 & 2.8258 & 1.2070 & -0.0272 & -0.0172 & 0.0195\\
            \hline 
            \end{tabular}
        \end{center}

        A partir de esta tabla el polinomio se obtiene facilmente\\
        $p(x) = 0.6747 + 0.8723(x - 1) + 1.2218(x - 1)(x - 1.2) + 0.0160(x - 1)(x - 1.2)(x - 1.4) - 0.0368(x - 1)(x - 1.2)(x - 1.4)(x - 1.6) + 0.0195(x - 1)(x - 1.2)(x- 1.4)(x - 1.6)(x - 1.8)(x -2)$\\    
        
        \subsection{Polinomio de Lagrange}
        Dados $n + 1$ puntos $(x_0, y_0), (x_1, y_1) , ..., (x_n, y_n)$ el polinomio de Lagrange tiene la siguiente forma:\\
        \begin{center}
            $\sum_{k=0}^{n} L_k(x)f(x_k)$\\ 
        \end{center}
        $donde$ \\ 
        \begin{center}
            $L_k(x) = \frac{(x-x_0)(x-x_1) ... (x-x_{k-1})(x-x_{k+1}) ... (x-x_n)}{(x_k-x_0)(x_k-x_1) ... (x_k-x_{k-1})(x_k-x_{k+1}) ... (x-x_n)}$\\
        \end{center}

        \begin{algorithm}[H]
            \caption{Algoritmo para obtener el polinomio de Lagrange}
            Leer $nPuntos, valor, x, y$\\
            $resultado \leftarrow 0$\\
            $pol \leftarrow 'P(x) = '$\\
            \For{$k \leftarrow 0$ \KwTo $nPuntos$}
            {
                $mult \leftarrow nPuntos$\\
                \For{$i \leftarrow 0$ \KwTo $nPuntos$}
                {
                    \If{$i \neq k$}
                    {
                        $mult \leftarrow mult * \frac{valor - x_i}{x_k - x_i}$\\
                        $num \leftarrow (x - x_i)$\\
                        $den \leftarrow x_k - x_i$\\
                        $term \leftarrow term + '[( num / den)]'$\\
                    }
                }
                Imprimir $'L_k = y_k * term'$\\
                $pol \leftarrow pol + 'y_k * term'$\\
                $resultado = resultado + mult * y_k$\\
            }
            Imprimir $pol$\\
            Retornar $resultado$\\
        \end{algorithm}

        \begin{thebibliography}{9}
            \bibitem{algebralineal}
            Orlando García Jaimes, Jairo A. Villegas Gutiérrez, Jorge Iván. \textit{Álgebra Lineal}. Editorial EAFIT, Medellín 2012. 
        \end{thebibliography}
    \end{document}  